{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "from model import CNN, Linear\n",
    "from torch import nn, optim\n",
    "import wandb\n",
    "import bios\n",
    "from keras.callbacks import TensorBoard\n",
    "from torch.utils.data import TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from typing import Callable, Tuple, Union, Optional, List\n",
    "\n",
    "\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    parts = []\n",
    "    for r in range(0, image.shape[0], 50):\n",
    "        for c in range(0, image.shape[1], 50):\n",
    "            parts.append(image[r : r + 50, c : c + 50, :])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "\n",
    "Produces a tensor of size (5120000,50,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6400, 50, 50, 3])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = os.listdir(f\"{data_dir}/raw/train\")\n",
    "\n",
    "\n",
    "def make_tensor(files: List[str]) -> torch.Tensor:\n",
    "    train_images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = Image.open(f\"{data_dir}/raw/train/{file}\")\n",
    "        image = np.array(image)\n",
    "        cropped_image = crop(image)\n",
    "        train_images.append(cropped_image)\n",
    "\n",
    "    return torch.Tensor(np.concatenate(train_images))\n",
    "\n",
    "\n",
    "tensor = make_tensor(somefiles)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "\n",
    "Produces a tensor of size (80000, 64, 50, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 50, 50, 3])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_tensor2(files: List[str]) -> torch.Tensor:\n",
    "    train_images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = Image.open(f\"{data_dir}/raw/train/{file}\")\n",
    "        image = np.array(image)\n",
    "        cropped_image = crop(image)\n",
    "        train_images.append(cropped_image)\n",
    "\n",
    "    return torch.Tensor(np.array(train_images))\n",
    "\n",
    "\n",
    "somefiles = train_files[:100]\n",
    "\n",
    "tensor = make_tensor2(somefiles)\n",
    "tensor.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e6c4ce725f74e7e2d791152d1c49900eadd59140924e72506b54ef17461f95d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('my_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
